{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BrainTriage - Group 3 - AngryChickens\n",
    "\n",
    "Chihab Amghane, s4112288<br>\n",
    "Freek van den Bergh, s4801709<br>\n",
    "Max Driessen, s4789628<br>\n",
    "Jordy Naus, s4722426<br>\n",
    "Marlous Nijman, s4551400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook expects the following file structure:\n",
    "```\n",
    "data/\n",
    "    BrainTriage/\n",
    "        final_test_split/\n",
    "        train/\n",
    "ISMI-braintriage/\n",
    "    code/\n",
    "        full-pipeline.ipynb (this notebook)\n",
    "    old-code/\n",
    "        ..\n",
    "```\n",
    "where `Braintriage/train/` and `BrainTriage/final_test_split/` are the original train and test data as provided by the competion, respectively, and `ISMI-braintriage` is our GitHub repository.\n",
    "\n",
    "The data can be moved or accessed from a different location by modifying the `ORIGINAL_DATA_PATH` variable in the *Generate Slice Data* section below. **However**, note that the code still expects the following file structure:\n",
    "```\n",
    "ORIGINAL_DATA_PATH/\n",
    "    final_test_split/\n",
    "    train/\n",
    "```\n",
    "It is advised to leave the other variables intact, since the code has been tested to work with this set-up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Import from repository\n",
    "from utils import clean_up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Slice Data\n",
    "\n",
    "As noted above, the `ORIGINAL_DATA_PATH` variable can be changed to the path where the original data resides. Note that the code still expects a specific file structure specified above though.\n",
    "\n",
    "If the specified directories do not exist already, this section will extract all slices for every patient from the original train and test data and save them in the specified directories (`SLICED_DATA_DIR`, `TRAIN_PATH`, and `TEST_DIR`). Additionally, a `.csv` file will be created to store the labels of each slice and patient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data\n",
      "../../data/BrainTriage\n",
      "../../data/sliced-data\n",
      "../../data/sliced-data/train\n",
      "../../data/sliced-data/test\n",
      "../../data/data-split\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = os.path.join(\"..\",\"..\",\"data\")\n",
    "ORIGINAL_DATA_PATH = os.path.join(DATA_DIR,\"BrainTriage\")\n",
    "SLICED_DATA_DIR = os.path.join(DATA_DIR, \"sliced-data\")\n",
    "TRAIN_PATH = os.path.join(SLICED_DATA_DIR, \"train\")\n",
    "TEST_PATH = os.path.join(SLICED_DATA_DIR, \"test\")\n",
    "DATA_SPLIT_DIR = os.path.join(DATA_DIR, \"data-split\")\n",
    "TMP_DIR = \"tmp\"\n",
    "SUBMISSION_DIR = os.path.join(\"..\", \"..\", \"submission\")\n",
    "print(DATA_DIR, ORIGINAL_DATA_PATH, SLICED_DATA_DIR, TRAIN_PATH, TEST_PATH, DATA_SPLIT_DIR, TMP_DIR, SUBMISSION_DIR, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(TRAIN_PATH):\n",
    "    !python3 dataset/create_slices.py -d $ORIGINAL_DATA_PATH -o $SLICED_DATA_DIR --train\n",
    "if not os.path.exists(TEST_PATH):\n",
    "    !python3 dataset/create_slices.py -d $ORIGINAL_DATA_PATH -o $SLICED_DATA_DIR --test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train/Validation Split\n",
    "\n",
    "In this section, the train/validation split will be defined for our entire pipeline, since we should use the same train/validation split for all networks in our pipeline. This split will be saved in `.csv` files in the directory specified in `DATA_SPLIT_DIR` above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(DATA_SPLIT_DIR):\n",
    "    !python3 dataset/create_data_split.py -k $K -d $TRAIN_PATH -ds $DATA_SPLIT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train ResNet34\n",
    "\n",
    "Here we train the convolutional neural network (CNN) (ResNet34) of our pipeline to classify the images. ResNet34 is trained on slice-level. Note that we have added a seed (`SEED`) during every training stage to ensure that are results are reproducible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_NAME = RESNET_TYPE = \"resnet34\"\n",
    "SEED = 420\n",
    "LR = 0.0001\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 16\n",
    "N_FEATURES = 128\n",
    "FLIP_PROBABILITY = ROTATE_PROBABILITY = 0.5\n",
    "MODEL_DIR = \"../../models\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 train/train-resnet.py $CNN_NAME $RESNET_TYPE -s $SEED -lr $LR -e $EPOCHS -b $BATCH_SIZE  \\\n",
    "                               -m $MODEL_DIR -f $N_FEATURES -d $TRAIN_PATH -ds $DATA_SPLIT_DIR \\\n",
    "                               -afp $FLIP_PROBABILITY -arp $ROTATE_PROBABILITY -ts 0 32 --tuple "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train LSTM (Freeze ResNet34)\n",
    "\n",
    "Here we train the LSTM of our pipeline. We do this by stripping ResNet34 from its classification layer, such that it outputs feature vectors, and training the LSTM to classify the images based on ResNet34's feature vectors. ResNet34 is frozen, such that it does not learn. The LSTM is trained on patient-level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(TMP_DIR, CNN_NAME), 'r') as f:\n",
    "    CNN_LOC = f.read()\n",
    "LSTM_NAME = \"lstm\"\n",
    "BATCH_SIZE = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 train/train-lstm.py $LSTM_NAME $RESNET_TYPE -s $SEED -d $TRAIN_PATH -ds $DATA_SPLIT_DIR -c $CNN_LOC \\\n",
    "                             -lr $LR -e $EPOCHS -b $BATCH_SIZE -m $MODEL_DIR -f $N_FEATURES \\\n",
    "                             -afp $FLIP_PROBABILITY -arp $ROTATE_PROBABILITY -ts 0 32 --tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune CombinedNet\n",
    "\n",
    "Here we finetune both ResNet34 and the LSTM with a smaller learning rate. This finetuned network will do the final classification on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(TMP_DIR, LSTM_NAME), 'r') as f:\n",
    "    LSTM_LOC = f.read()\n",
    "COMBINED_NAME = \"combinednet\"\n",
    "LR = 0.000001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 train/train-combinednet.py $COMBINED_NAME $RESNET_TYPE -s $SEED -d $TRAIN_PATH -ds $DATA_SPLIT_DIR \\\n",
    "                                    -l $LSTM_LOC -lr $LR -e $EPOCHS -b $BATCH_SIZE -m $MODEL_DIR -f $N_FEATURES \\\n",
    "                                    -afp $FLIP_PROBABILITY -arp $ROTATE_PROBABILITY -ts 0 32 --tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Test Data\n",
    "\n",
    "Make predictions on the test data with the final finetuned combined network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(TMP_DIR, COMBINED_NAME), 'r') as f:\n",
    "    COMBINED_FILENAME = os.path.basename(os.path.normpath(f.read()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 test/submission.py $COMBINED_NAME $RESNET_TYPE $COMBINED_FILENAME -d $TEST_PATH -m $MODEL_DIR \\\n",
    "                            -sd $SUBMISSION_DIR -b $BATCH_SIZE -f $N_FEATURES -ts 0 32 --tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean-up\n",
    "\n",
    "Remove temporary directory that was created in the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_up()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
